\title{Graduate School Pre-exam Solution}
\author{Daeyoung Lim}

\documentclass[answers]{exam}
\usepackage[left=3cm,right=3cm,top=3.5cm,bottom=2cm]{geometry}
\usepackage{amssymb,amsmath}
\usepackage{kotex}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{courier}
\usepackage{cancel}
\usepackage{array}
\usepackage{courier}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage[usenames, dvipsnames]{color}
\setcounter{secnumdepth}{4}
\lstset{
         basicstyle=\footnotesize\ttfamily, % Standardschrift
         %numbers=left,               % Ort der Zeilennummern
         numberstyle=\tiny,          % Stil der Zeilennummern
         %stepnumber=2,               % Abstand zwischen den Zeilennummern
         numbersep=5pt,              % Abstand der Nummern zum Text
         tabsize=2,                  % Groesse von Tabs
         extendedchars=true,         %
         breaklines=true,            % Zeilen werden Umgebrochen
         keywordstyle=\color{red},
            frame=b,         
 %        keywordstyle=[1]\textbf,    % Stil der Keywords
 %        keywordstyle=[2]\textbf,    %
 %        keywordstyle=[3]\textbf,    %
 %        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
         stringstyle=\color{white}\ttfamily, % Farbe der String
         showspaces=false,           % Leerzeichen anzeigen ?
         showtabs=false,             % Tabs anzeigen ?
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         %backgroundcolor=\color{lightgray},
         showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
 }
 \lstloadlanguages{% Check Dokumentation for further languages ...
         %[Visual]Basic
         %Pascal
         %C
         %C++
         %XML
         %HTML
         Java
 }
    %\DeclareCaptionFont{blue}{\color{blue}} 

\definecolor{myblue}{RGB}{72, 165, 226}
\definecolor{myorange}{RGB}{222, 141, 8}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\setlength{\heavyrulewidth}{1.5pt}
\setlength{\abovetopsep}{4pt}
\setlength{\parindent}{0mm}
\linespread{1.3}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\csch}{csch}
\DeclareMathOperator{\argmin}{\arg\!\min}
\DeclareMathOperator{\Tr}{Tr}

\newcommand{\bs}{\boldsymbol}
\newcommand{\opn}{\operatorname}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % We use newtheorem to define theorem-like structures
% %
% % Here are some common ones. . .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{scolium}{Scolium}   %% And a not so common one.
\newtheorem{definition}{Definition}
\newenvironment{proof}{{\sc Proof:}}{~\hfill QED}
\newenvironment{AMS}{}{}
\newenvironment{keywords}{}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %   The first thanks indicates your affiliation
% %
% %  Just the name here.
% %
% % Your mailing address goes at the end.
% %
% % \thanks is also how you indicate grant support
% %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\setstretch{1.5} %줄간격 조정
\newpage
\firstpageheader{}{}{\bf\large Daeyoung Lim \\ Grad School \\ Year of 2008, early}
\runningheader{Daeyoung Lim}{Graduate School Pre-exam}{2007 early}
\begin{questions}
   \question
   이항시행(Binomial trial) $\mathrm{Bin}\left(10,\theta\right)$에서 $X=9$가 관측되었다 (즉, $n=10$이고 $x=9$).
   \begin{enumerate}
      \item $H_{0}:\theta=0.5$ 대 $H_{1}:\theta>0.5$의 검정을 하고자 한다. 이를 위해 정확한 p-값을 구하라.
      \item $\theta$에 대한 사전분포로 (0,1)에서의 균일분포(uniform distribution)가 상정되었다고 하자. $\theta \leq 0.5$의 사후확률을 정확히 구하라. 즉, $\mathrm{Pr}\left(\theta\leq0.5\,|\, n=10,x=9\right)$은 얼마인가?
   \end{enumerate}
   \begin{solution}
      \begin{enumerate}
         \item $\mathrm{Pr}\left(X> 9\,|\,\theta=0.5\right)=11\times0.5^{10}$. 더 이상 설명할 게 없다.
         \item 간단하게 Bayesian 추정방법에 대해서 설명을 덧붙인다. Bayesian statistics에서 사후분포(posterior distribution) 모든 것이라 할 수 있다. 모든 추정방법은 사후분포를 구하기 위한 것인데 시작은 이러하다. 우리가 샘플을 관측할 때 지금까지는 $X_{1},X_{2},\ldots ,X_{n}$이 정규분포, 혹은 지금과 같이 이항분포를 따른다고 가정한다. 하지만 Bayesian은 이 샘플이 어떤 모수에 의존한다고 생각한다. 예를 들어 정규분포에서는 평균 $\mu$나 분산 $\sigma^{2}$이 주어져야만, 혹은 이항분포에서 확률 $p$가 주어져야만 어떤 분포에 대해서 얘기할 수 있다는 것이다. (이항분포에서 시행횟수 $n$은 대부분의 경우 모수로 다루지는 않는다.) 즉 우리는 $X_{1},\ldots,X_{n}|\mu,\sigma^{2}$가 정규분포라고 말하고 있는 것이고 $X_{1},\ldots,X_{n}|p$이 이항분포를 따른다고 표현한다는 것이다. 그리고 목적지인 사후분포는 샘플을 관측했을 때 모수가 따를 분포이다. 예를 들어 $\mu|X_{1},\ldots, X_{n}$나 $p|X_{1},\ldots, X_{n}$이다. \par
         임의의 모수를 $\theta$라고 할 때 사후분포는 다음과 같이 구해진다.
         \begin{equation}
            p\left(\theta|X_{1},\ldots,X_{n}\right) = \dfrac{p\left(X_{1},\ldots,X_{n}|\theta\right)p\left(\theta\right)}{\int p\left(X_{1},\ldots,X_{n}|\theta\right)p\left(\theta\right)\, d\theta}
         \end{equation}는
         많은 경우 (1)의 분모에 있는 적분이 폐쇄형(closed form; 존재하지만 초등함수의 결합으로 표현되지 않음)으로 떨어지지 않아 \emph{Markov Chain Monte Carlo(MCMC)}와 같은 시뮬레이션에 기반을 둔 샘플링 추정법이나 deterministic한 \emph{variational approximation}과 같은 근사 방법을 통해 추정한다.\par
         현재 문제에서 주어진 것은 간단한 Beta-Binomial 문제로서 사후분포가 정확하게 우리가 아는 분포로 떨어지는 경우이다. 사실 이런 경우가 지수족(Exponential Family)에서만 발생하며, 사전분포와 사후분포가 모수가 다른 같은 분포가 된다. 이를 켤레사전분포(conjugate prior)라 한다. Beta 분포는 Binomial 분포의 켤레사전분포로서 사후분포 역시 Beta 분포가 된다. 즉,
         \begin{align}
          p\left(\theta|x\right) &\propto p\left(x|\theta\right)p\left(\theta\right)\\
          &\propto \theta^{x}\left(1-\theta\right)^{10-x}\cdot 1\\
          &\sim \mathrm{Be}\left(x+1,11-x\right).
         \end{align}
         따라서 $\mathrm{Pr}\left(\theta\leq0.5\,|\,n=10,x=9\right)$는 $\mathrm{Be}\left(10,2\right)$를 적분하면 된다.
         \begin{align}
          \mathrm{Pr}\left(\theta\leq 0.5|x=9\right) &= \int_{0}^{0.5}\dfrac{\Gamma\left(12\right)}{\Gamma\left(10\right)\Gamma\left(2\right)}\theta^{9}\left(1-\theta\right)\,d\theta\\
          &= 110\left[\dfrac{\theta^{10}}{10}-\dfrac{\theta^{11}}{11} \right]_{0}^{0.5}\\
          &= \dfrac{1}{2^{11}}\left(22-10\right)\\
          &= \dfrac{3}{512}
         \end{align}
      \end{enumerate}
   \end{solution}
   \question
   $X_{1},X_{2},\ldots, X_{n}$을 평균이 $\mu$이고 분산이 $\sigma^{2}$인 분포로부터의 임의표본이라고 할 때
   \begin{enumerate}
    \item $S^{2}=\dfrac{1}{n+1}\displaystyle \sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{2}$가 $\sigma^{2}$의 일치추정량임을 보이고
    \item 임의표본의 가정에 정규분포의 가정을 추가햇을 때의 위의 $S^{2}$의 $\sigma^{2}$에 대한 MSE(Mean Squared Error)을 구하시오.
   \end{enumerate}
   \begin{solution}
    \begin{enumerate}
      \item 일치추정량의 정의를 이용해서 보이는 방법이 있고 대수의 법칙에 의해 이미 확률수렴함을 알고 있는 통계량을 이용해 보일 수 있다. 
      \begin{itemize}
      \item 먼저 첫번째 정의를 이용한 증명이다. 마코프 부등식(Markov inequality)에 의해 다음의 부등식이 성립한다.
      \begin{equation}
        \mathrm{Pr}\left(\left|S_{n}-\sigma^{2}\right|\geq \epsilon\right) \leq \dfrac{\mathrm{E}\left(\left|S_{n}-\sigma^{2}\right|\right)}{\epsilon}
      \end{equation}
      $\left|S_{n}-\sigma^{2}\right|$은 음수일 수도 있고 양수도 있지만 어차피 나중에 무관해진다. 우선 양수라 치고 
      \begin{equation}
        \mathrm{E}\left(S_{n}\right)-\sigma^{2} = \dfrac{n-1}{n+1}\sigma^{2}-\sigma^{2}
      \end{equation}
      이다. $\left(n-1\right)^{-1}\sum_{i=1}^{n}\left(X_{n}-\overline{X}_{n}\right)^{2}$가 비편향추정량임을 알고 있기 때문에 이를 이용하면 바로 나온다. 따라서 이를 (9)에 대입하여 극한을 취하면
      \begin{align}
        \lim_{n\to\infty}\mathrm{Pr}\left(\left|S_{n}-\sigma^{2}\right|\geq \epsilon\right) &= \lim_{n\to\infty}\dfrac{1}{\epsilon}\left(\dfrac{n-1}{n+1}\sigma^{2}-\sigma^{2}\right)\\
        &= 0
      \end{align}
      고로 $S^{2}$는 $\sigma^{2}$의 일치추정량이다.
      \item 다음은 표본적률이 모적률로 확률수렴한다는 대수의 법칙을 이용한 증명이다. 즉
      \begin{equation}
        \dfrac{1}{n}\sum_{i=1}^{n}X_{i}^{k}\; \xrightarrow{p} \; \mathrm{E}\left(X_{1}^{k}\right).
      \end{equation}
      $S^{2}$를 전개하면
      \begin{equation}
        S^{2} = \dfrac{n}{n+1}\overline{X^{2}_{n}}-\dfrac{n}{n+1}\left(\overline{X}_{n}\right)^{2}
      \end{equation}
      이고 $\overline{X^{2}_{n}}=n^{-1}\sum_{i=1}^{n}X_{i}^{2}$, 2차 표본적률이다. 따라서 이는 다음과 같이 확률수렴한다.
      \begin{equation}
        S^{2} \xrightarrow{p} \mathrm{E}\left(X_{1}^{2}\right) - \left(\mathrm{E}\left(X_{1}\right)\right)^{2}
      \end{equation}
      1차 표본적률의 제곱이 모적률의 제곱으로 확률수렴한다는 것은 Slutsky 정리의 결과이다. 다시 말해 $X$와 $Y$가 각각 $\mu$와 $\nu$로 확률수렴하면 그 곱도 곱으로 확률수렴한다. 따라서
      \begin{equation}
        S^{2} \xrightarrow{p} \left(\sigma^{2}+\mu^{2}\right) - \mu^{2} = \sigma^{2}
      \end{equation}
      \end{itemize}
      \item MSE는 다음과 같이 분해할 수 있다 (Variance-bias decomposition).
      \begin{equation}
        \mathrm{MSE}\left(X\right) = \mathrm{Bias}^{2}\left(X\right) + \mathrm{Var}\left(X\right)
      \end{equation}
      이를 이용하여 분산을 계산할 때 정규분포 가정이 없으면 인생이 비참해진다. 왜냐하면 정규성 가정이 있으면 대충 카이제곱 분포를 통해 유도해낼 수 있기 때문이다. 먼저 앞서 $\mathrm{E}\left(S^{2}\right)$은 구했다. 그러므로 편향의 제곱은 다음과 같다.
      \begin{equation}
        \mathrm{Bias}^{2}\left(S^{2}\right) = \left(\dfrac{n-1}{n+1}\sigma^{2}-\sigma^{2}\right)^{2}=\dfrac{4\sigma^{4}}{\left(n+1\right)^{2}}
      \end{equation}
      그리고 분산을 구하기에 앞서 $\sigma^{-2}\sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{2}\sim \chi^{2}\left(n-1\right)$임을 이용해보자. 그리고 카이제곱분포와 감마분포와의 관련성을 이용하자.
      \begin{align}
        S^{2} &= \dfrac{\sum_{i=1}^{n}\left(X_{i}-\overline{X}_{n}\right)^{2}}{\sigma^{2}}\dfrac{\sigma^{2}}{n+1}\\
        &\sim \mathrm{Ga}\left(\dfrac{n-1}{2},\dfrac{n+1}{2\sigma^{2}}\right)\\
        \mathrm{Var}\left(S^{2}\right) &= \dfrac{2\left(n-1\right)\sigma^{4}}{\left(n+1\right)^{2}}
      \end{align}
      따라서,
      \begin{align}
        \mathrm{MSE}\left(S^{2}\right) &= \dfrac{4\sigma^{4}}{\left(n+1\right)^{2}}+\dfrac{2\left(n-1\right)\sigma^{4}}{\left(n+1\right)^{2}}\\
        &= \dfrac{2\sigma^{4}}{n+1}
      \end{align}
    \end{enumerate}
   \end{solution}
   \question
   확률변수 $X$가 시행횟수가 $n$이고 성공확률이 $p$인 이항분포 $\mathrm{Bin}\left(n,p\right)$를 따른다고 하자.
   \begin{enumerate}
    \item 귀무가설 $H_{0}:p=1/4$ 대 대립가설 $H_{1}:p=1/2$에 대한 최강력(most powerful) 검정법이 존재한다면 유의수준 $\alpha=0.05$로 구하고, 구한 검정방법의 검정력을 구하시오.
    \item 문항 1에서 구한 검정법에 대해 $n$이 큰 경우 근사 임계값을 중심극한정리에 의해 구하시오. 단, 중심극한정리를 정확히 설명하고 이를 근사 임계값을 구하는 데 사용할 수 있는 이유를 쓰시오.
    \item 귀무가설 $H_{0}:p=1/2$ 대 대립가설 $H_{1}:p>1/2$에 대한 균일 최강력 검정방법이 존재한다면 유의수준 $\alpha=0.05$로 구하시오.
    \item 귀무가설 $H_{0}:p=1/2$ 대 $H_{1}:p\neq 1/2$에 대한 균일 최강력 검정 방법이 존재한다면 유의수준 $\alpha = 0.05$로 구하시오.
    \item 귀무가설 $H_{0}:p=1/2$ 대 대립가설 $H_{1}:p\neq 1/2$에 대한 유의수준 $\alpha=0.05$인 일반화 가능도비(likelihood ratio) 검정방법을 구하시오. \par
    (힌트: $\lambda\left(x\right)$를 가능도비라고 하면 $x\leq n/2$이면 $\lambda\left(x\right)$는 $-\left(2x-n\right)$에 대한 증가함수이며 $\lambda\left(x\right)=\lambda\left(n-x\right)$임을 보인 후, 검정방법을 구할 것.)
   \end{enumerate}
   \begin{solution}
    \begin{itemize}
      \item 가능도비를 계산하면
      \begin{align}
        \dfrac{L_{0}}{L_{1}} &= \dfrac{\left(0.25\right)^{x}\left(0.25\times 3\right)^{n-x}}{\left(0.5\right)^{x}}\\
        &= \left(\dfrac{3}{2}\right)^{n}\dfrac{1}{3}^{x} \geq c
      \end{align}
      이를 정리하면 $c' \geq x$일 때 귀무가설을 기각하는 것이 최강력 검정이 됨을 알 수 있다. 어떤 상수 $c'$는 유의확률이 $\alpha$(유의수준)과 같아지는 상수값을 찾으면 된다. 하지만 이 경우 이산확률분포이므로 정확히 $\alpha=0.05$가 되는 값이 없을 수도 있고, 그러한 경우 
      \begin{equation}
        \sum_{x=c'}^{n}{{n}\choose{x}}\left(0.25\right)^{x}\left(0.75\right)^{n-x} \leq 0.05
      \end{equation}
      인 최소의 양의 정수를 찾으면 된다. 그리고 검정력은 다음과 같다.
      \begin{equation}
        1-\beta = 1-\sum_{x=0}^{c'-1}{{n}\choose{x}}\left(0.5\right)^{n}
      \end{equation}
      \item 중심극한정리에서 가장 중요한 가정은 2차 적률이 유한하다는 것이다. 이는 Measure theory의 언어로 확률변수 $X$가 $L_{2}$ space에 속한다는 것이다. 즉, 분산이 유한한 확률변수에서 서로 독립인 임의표본을 뽑은 경우 표본평균이 점근적으로(asymptotically) 정규분포를 따른다는 정리이다. 중심극한정리를 쓸 수 있으려면 다음 두 조건을 만족해야 한다.
      \begin{itemize}
        \item $\mathrm{E}\left|X\right|^{2}<\infty$ (확률공간과 같이 유한 측도 공간(finite measure space)를 가정할 경우 $1\leq p<q\leq \infty$에 대해서 $\mathrm{E}\left(X^{q}\right)<\infty$하면 반드시 $\mathrm{E}\left(X^{p}\right)<\infty$하다. 다시 말해 2차 적률이 유한하다는 말은 1차 적률 또한 유한하다는 뜻이다.)
        \item $X_{1},X_{2},\ldots,X_{n}$이 서로 독립이다.
      \end{itemize}
      중심극한정리 중 이항분포가 정규근사될 수 있다는 것은 특별히 \emph{DeMoivre-Laplace Theorem}이라 부르고 수학적으로 표현하면 다음과 같다.
      \begin{equation}
        Y_{i}\overset{\text{iid}}{\sim}\mathrm{Ber}\left(p\right) \implies X \equiv \sum_{i=1}^{n}Y_{i} \sim \mathrm{Bin}\left(n,p\right)
      \end{equation}
      서로 독립인 $n$개의 베르누이 확률변수의 합이므로 중심극한정리에 따라 그 평균을 정규분포로 근사시킬 수 있다. \par
      임계값을 구해보면 $\overline{X}_{n}=n^{-1}X$라 할 때 $\overline{X}_{n} \sim \mathcal{N}\left(p, n^{-1}p\left(1-p\right)\right)$이므로 
      \begin{equation}
        \dfrac{\sqrt{n}\left(\overline{X}_{n}-p\right)}{\sqrt{p\left(1-p\right)}} \xrightarrow{d} \mathcal{N}\left(0,1\right)
      \end{equation}
      이고 1에서 구한 기각역에 따라 다음이 성립하는 $c'$를 찾으면 된다.
      \begin{equation}
        \mathrm{Pr}\left(\dfrac{\sqrt{n}\left(\overline{X}_{n}-p\right)}{\sqrt{p\left(1-p\right)}} \geq \dfrac{\sqrt{n}\left(c'/n-p\right)}{\sqrt{p\left(1-p\right)}}\right) = 0.05
      \end{equation}
      따라서 이를 통해
      \begin{equation}
        \dfrac{\sqrt{n}\left(c'/n-p\right)}{\sqrt{p\left(1-p\right)}} = z_{0.05} \implies c'=\sqrt{np\left(1-p\right)}z_{0.05}+np
      \end{equation}
      \item $p_{1}$를 $p_{1}>1/2$를 만족하는 어떤 모수로 놓고 가능도비를 계산하면
      \begin{equation}
        \dfrac{L_{0}}{L_{1}} = \left(\dfrac{1-p_{1}}{p_{1}}\right)^{x} \leq k
      \end{equation}
      이 기각역이 되고 $p_{1}>1/2$이므로 위의 함수는 $x$에 대하여 단조감소하는 함수가 된다. 따라서 어떤 상수 $k$보다 작아지려면 $x$가 충분히 커야 하므로 $c'\geq x$이 기각역이 될 것이다. (가능도비가 단조로우므로(?) 균일 최강력 검정법이 존재한다.) $c'$값은 1에서와 같이
      $$
        \sum_{x=c'}^{n}{{n}\choose{x}}0.5^{x}\leq 0.05
      $$
      를 만족하는 최소의 양의 정수를 찾는다.
      \item 앞서 보였듯이 대립가설의 모수를 $p_{1}$로 놓고 가능도비를 구하면
      $$
        \left(\dfrac{1-p_{1}}{p_{1}}\right)^{x} \leq k
      $$
      의 형태로 나오게 되는데 $p_{1}>1/2$일 경우 단조감소, $p_{1}<1/2$일 경우 단조증가하므로 균일 최강력 검정 방법이 존재하지 않는다.
      \item 일반화 가능도비 검정법을 쓰기 위해서는 MLE를 알아야 한다. 이항분포에서 MLE는 $\hat{p}=x/n$라는 것을 안다고 치고 가능도비를 구하면
      \begin{align}
        \lambda &= \left(\dfrac{1-\hat{p}}{\hat{p}}\right)^{x}\left(\dfrac{0.5}{\hat{p}}\right)^{n}\\
        &= \left(\dfrac{1-\hat{p}}{\hat{p}}\right)^{n\hat{p}}\left(\dfrac{0.5}{\hat{p}}\right)^{n}\\
        \ln \lambda &= n\left(\hat{p}-1\right)\ln\left(1-\hat{p}\right)-n\hat{p}\ln \hat{p}-n\ln 2\\
        \dfrac{d \ln \lambda}{d\hat{p}} &= n\ln \left(\dfrac{1-\hat{p}}{\hat{p}}\right)
      \end{align}
      이고 로그가능도비의 도함수가 0이 되는 지점은 $\hat{p}=1/2$이다. 로그가능도비가 증가하다 $\hat{p}=1/2$를 기점으로 다시 감소하는 형태이므로 $\ln \lambda \leq k$이기 위해서는 $\hat{p}$가 충분히 크거나 충분히 작아야 한다. 즉 기각역이 다음과 같다.
      $$
        \hat{p}\leq c_{1} \quad \text{or} \quad \hat{p} \geq c_{2}\;\left(c_{1}\leq c_{2}\right)
      $$
      따라서 
      \begin{align}
        \sum_{x=0}^{c_{1}}{{n}\choose{x}}0.5^{n} &\leq 0.025\\
        \sum_{x=c_{2}}^{n}{{n}\choose{x}}0.5^{n} &\leq 0.025
      \end{align}
      를 만족하는 상수값들을 찾으면 된다.
    \end{itemize}
   \end{solution}
   \question
   Let $X_{1},\ldots, X_{n}$ be a random sample from $f\left(x;\lambda\right)=\lambda\exp\left(-\lambda x\right)$, where $0<x<\infty$. We want to test $H_{0}:\lambda \leq \lambda_{0}$ versus $H_{1}:\lambda > \lambda_{0}$. Obtain the uniformly most powerful (UMP) test with size $\alpha$.
   \begin{solution}
    그만 좀 물어봐라. 가능도 두 개 나눠.
   \end{solution}
   \question
   절편이 없는 단순선형회귀모형
   $$
    Y=\beta_{1}X_{1}+\epsilon
   $$
   을 고려하자. 여기서, $Y$는 반응변수를, $X_{1}$은 설명변수를, 그리고 $\beta_{1}$은 회귀계수를 의미하며 오차항 $\epsilon$은 평균이 0, 분산이 $\sigma^{2}$이라 가정한다.
   \begin{enumerate}
    \item $\beta_{1}$의 최소제곱추정량(least squares estimator)을 구하시오. (10점)
    \item 반응변수 $Y$에 대한 옳은 회귀 모형이 위의 단순선형회귀모형이 아니라 
    $$
      Y = \beta_{1}X_{1}+\beta_{2}X_{2}+\epsilon
    $$
    이었다고 가정하자. 여기서, $X_{2}$는 실수로 포함되지 않은 $X_{1}$과 다른 설명변수를 의미하며 $\beta_{2}$는 $X_{2}$의 회귀계수를 의미한다. 1에서 구한 최소제곱추정량이 비편향추정량(unbiased estimator)이 되는지 여부를 보이시오. (10점)
    \item 2의 회귀모형이 옳은 모형일 때 1에서 구한 $\beta_{1}$의 최소제곱추정량의 분산을 구하시오. (5점)
   \end{enumerate}
   \pagebreak
   \begin{solution}
    \begin{enumerate}
      \item $\epsilon_{i} = Y_{i}-\beta_{1}x_{1i}$이므로
      \begin{align}
        \dfrac{d}{d\beta_{1}}\sum_{i=1}^{n}\left(Y_{i}-\beta_{1}x_{1i}\right)^{2} &= -2\sum_{i=1}^{n}x_{1i}\left(Y_{i}-\beta_{1}x_{1i}\right)=0\\
        \widehat{\beta}_{1} &= \dfrac{\sum_{i=1}^{n}x_{1i}Y_{i}}{\sum_{i=1}^{n}x_{1i}^{2}}.
      \end{align}
      \item Omitted variable bias가 나타날 것임이 분명하다. 수학적으로 증명하자면 다음과 같다. 1에서 구한 $\widehat{\beta}_{1}$에 $Y_{i}$가 있다. 여기에 참인 모형을 대입하자.
      \begin{align}
        \mathrm{E}\left(\widehat{\beta}_{1}\right) &= \mathrm{E}\left(\dfrac{\sum_{i=1}^{n}x_{1i}Y_{i}}{\sum_{i=1}^{n}x_{1i}^{2}}\right)\\
        &= \dfrac{1}{\sum_{i=1}^{n}x_{1i}^{2}}\sum_{i=1}^{n}x_{1i}\mathrm{E}\left(Y_{i}\right)\\
        &= \dfrac{1}{\sum_{i=1}^{n}x_{1i}^{2}}\sum_{i=1}^{n}x_{1i}\left(\beta_{1}x_{1i}+\beta_{2}x_{2i}\right)\\
        &= \beta_{1}+\beta_{2}\left(\dfrac{\sum_{i=1}^{n}x_{1i}x_{2i}}{\sum_{i=1}^{n}x_{1i}^{2}}\right) \\
        &\neq \beta_{1}
      \end{align}
      따라서 비편향추정량이 되지 못한다.
      \item \begin{align}
        \mathrm{Var}\left(\widehat{\beta}_{1}\right) &= \dfrac{1}{\left(\sum_{i=1}^{n}x_{1i}^{2}\right)^{2}}\mathrm{Var}\left(x_{11}Y_{1}+x_{12}Y_{2}+\cdots +x_{1n}Y_{n}\right)\\
        &= \dfrac{1}{\left(\sum_{i=1}^{n}x_{1i}^{2}\right)^{2}}\left(x_{11}^{2}\sigma^{2}+\cdots + x_{1n}^{2}\sigma^{2}\right)\\
        &= \dfrac{\sum_{i=1}^{n}x_{1i}^{2}}{\left(\sum_{i=1}^{n}x_{1i}^{2}\right)^{2}}\sigma^{2}\\
        &= \dfrac{\sigma^{2}}{\sum_{i=1}^{n}x_{1i}^{2}}
      \end{align}
    \end{enumerate}
   \end{solution}
\end{questions}
\end{document}
