\title{Graduate School Pre-exam Solution}
\author{Daeyoung Lim}

\documentclass[answers]{exam}
\usepackage[left=3cm,right=3cm,top=3.5cm,bottom=2cm]{geometry}
\usepackage{amssymb,amsmath}
\usepackage{kotex}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{courier}
\usepackage{cancel}
\usepackage{array}
\usepackage{courier}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage[usenames, dvipsnames]{color}
\setcounter{secnumdepth}{4}
\lstset{
         basicstyle=\footnotesize\ttfamily, % Standardschrift
         %numbers=left,               % Ort der Zeilennummern
         numberstyle=\tiny,          % Stil der Zeilennummern
         %stepnumber=2,               % Abstand zwischen den Zeilennummern
         numbersep=5pt,              % Abstand der Nummern zum Text
         tabsize=2,                  % Groesse von Tabs
         extendedchars=true,         %
         breaklines=true,            % Zeilen werden Umgebrochen
         keywordstyle=\color{red},
            frame=b,         
 %        keywordstyle=[1]\textbf,    % Stil der Keywords
 %        keywordstyle=[2]\textbf,    %
 %        keywordstyle=[3]\textbf,    %
 %        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
         stringstyle=\color{white}\ttfamily, % Farbe der String
         showspaces=false,           % Leerzeichen anzeigen ?
         showtabs=false,             % Tabs anzeigen ?
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         %backgroundcolor=\color{lightgray},
         showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
 }
 \lstloadlanguages{% Check Dokumentation for further languages ...
         %[Visual]Basic
         %Pascal
         %C
         %C++
         %XML
         %HTML
         Java
 }
    %\DeclareCaptionFont{blue}{\color{blue}} 

\definecolor{myblue}{RGB}{72, 165, 226}
\definecolor{myorange}{RGB}{222, 141, 8}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\setlength{\heavyrulewidth}{1.5pt}
\setlength{\abovetopsep}{4pt}
\setlength{\parindent}{0mm}
\linespread{1.3}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\csch}{csch}
\DeclareMathOperator{\argmin}{\arg\!\min}
\DeclareMathOperator{\Tr}{Tr}

\newcommand{\bs}{\boldsymbol}
\newcommand{\opn}{\operatorname}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % We use newtheorem to define theorem-like structures
% %
% % Here are some common ones. . .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{scolium}{Scolium}   %% And a not so common one.
\newtheorem{definition}{Definition}
\newenvironment{proof}{{\sc Proof:}}{~\hfill QED}
\newenvironment{AMS}{}{}
\newenvironment{keywords}{}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %   The first thanks indicates your affiliation
% %
% %  Just the name here.
% %
% % Your mailing address goes at the end.
% %
% % \thanks is also how you indicate grant support
% %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\setstretch{1.5} %줄간격 조정
\newpage
\firstpageheader{}{}{\bf\large Daeyoung Lim \\ Grad School \\ Year of 2008, late}
\runningheader{Daeyoung Lim}{Graduate School Pre-exam}{2008 late}
\begin{questions}
   \question
   다음 물음에 답하시오.
   \begin{enumerate}
    \item 크기 $n$인 표본 $\left\{x_{1},\ldots , x_{n} \right\}$에서 반복을 허용하여 $n$번 재추출할 때, 특정 자료값 (예컨대 $x_{1}$)이 재표본(크기 $n$)에 포함될 확률은? 이 확률은 $n\to \infty$에 따라 어느 값에 수렴하는가?
    \item 100년에 99년 정도 규모의 홍수에 대비하여 댐이 건설되었다고 하자. 따라서 이 댐은 100년에 1년 정도 규모의 큰 홍수에는 견디지 못하고 붕괴된다. 이 댐이 100년 이내에 붕괴될 확률은?
   \end{enumerate}
   \begin{solution}
    \begin{enumerate}
      \item 특정 자료값을 $x_{1}$이라 놓았을 때, 1번 재추출 시 그 자료값이 뽑힐 확률은 $n^{-1}$이다. 따라서 $n$번 뽑을 경우 $x_{1}$이 한번도 뽑히지 않을 확률은
      $$
        \left(1-\dfrac{1}{n}\right)^{n}
      $$
      이 되고 한 번이라도 뽑히면 재표본에 포함되는 것이므로 그럴 확률은
      $$
        1-\left(1-\dfrac{1}{n}\right)^{n}
      $$
      이 된다. $n\to\infty$할 때 이 확률은
      $$
        \lim_{n\to\infty}\left(1-\left(1-\dfrac{1}{n}\right)^{n}\right) = 1-e^{-1}
      $$
      이다.
      \item 거지같이 써놔도 찰떡같이 알아먹는지 보려는 문제이다. 그러니까 댐이 붕괴될 확률이 $1/100$이라는 것이니 100년 이내에 붕괴될 확률은 다음과 같다.
      $$
        \dfrac{1}{100} + \dfrac{99}{100}\dfrac{1}{100} + \cdots + \left(\dfrac{99}{100}\right)^{99}\dfrac{1}{100}= \sum_{n=0}^{99}\left(\dfrac{99}{100}\right)^{n}\dfrac{1}{100}
      $$
      등비수열의 합공식을 쓰면
      $$
        1-\left(\dfrac{99}{100}\right)^{100}
      $$
      이 된다.
    \end{enumerate}
   \end{solution}
   \question
   다음 물음에 답하시오.
   \begin{enumerate}
    \item $X_{1},\ldots, X_{n}$을 베르누이($p$)로부터 구한 랜덤표본이라고 할 때, 성공확률 $p$에 대한 크레이머-라오(Cramer-Rao) 정보부등식에 의한 비편향 추정량들이 가질 수 있는 분산의 하한값을 구하시오.
    \item $X_{1},\ldots , X_{n}$을 베르누이($p$)로부터 구한 랜덤표본이라고 할 때, 1에서 구한 크레이머-라오 하한값을 이용하여 표본평균 $\overline{X}_{n}=\left(X_{1}+\cdots +X_{n}\right)/n$이 균일 최소분산 추정량이 됨을 설명하시오.
    \item $X_{1},\ldots, X_{n}$을 베르누이($p$)로부터 구한 랜덤표본이라고 할 때 $p$와 $\log\left(p/\left(1-p\right)\right)$에 대한 최대가능도(maximum likelihood) 추정량을 각각 구하시오.
    \item $X_{1}, \ldots , X_{n}$이 일양분포 $\mathrm{Unif}\left(0,\theta\right)$로부터 구한 랜덤표본인 경우 크레이머-라오 하한값보다 분산이 작은 비편향 추정량이 존재하는가? 답에 대한 이유를 설명하시오.
   \end{enumerate}
   \begin{solution}
    \begin{enumerate}
      \item 크레이머-라오 하한값을 구하기 위해서는 피셔 정보량을 구해야 한다. 
      \begin{align}
        \mathcal{I}\left(p\right) &= -\mathrm{E}\left(\dfrac{d^{2}}{dp^{2}}\ln f\left(x|p\right)\right)\\
        &= \dfrac{1}{p\left(1-p\right)}
      \end{align}
      따라서 크레이머-라오 정보부등식은 다음과 같다.
      $$
        \mathrm{Var}\left(T\left(X_{1},\ldots,X_{n}\right)\right) \geq \dfrac{\left\{\mathrm{E}'\left(T\left(X_{1},\ldots,X_{n}\right)\right)\right\}^{2}}{n\mathcal{I}\left(p\right)}
      $$
      여기서 분자에 들어있는 통계량은 $p$의 비편향추정량이라 했으므로 미분하게 되면 1이 나온다. 따라서 하한값은 $n^{-1}p\left(1-p\right)$이다.
      \item 표본평균의 분산은 $n^{-1}p\left(1-p\right)$이므로 크레이머-라오 하한값과 동일해진다. 이를 most efficient estimator이라 하며 자동으로 UMVBUE가 된다. (모든 UMVUE가 반드시 크레이머-라오 하한과 같은 것은 아니고 같아질 경우에만 most efficient estimator이란 이름이 붙는다.)
      \item 최대가능도추정량(MLE)는 invariance property가 있다. 즉, $\hat{\theta}$가 $\theta$에 대한 MLE라면, 임의의 함수 $T$에 대하여 $T\left(\theta\right)$의 MLE는 $T\left(\hat{\theta}\right)$이다. 따라서 $p$의 MLE만 알면 $\ln\left(p/\left(1-p\right)\right)$는 자동으로 알게 된다.
      \begin{align}
        L\left(p|X_{1},\ldots,X_{n}\right) &= p^{\sum_{i=1}^{n}X_{i}}\left(1-p\right)^{n-\sum_{i=1}^{n}X_{i}}\\
        \ln L\left(p|X_{1},\ldots,X_{n}\right) &= \ln p \cdot \sum_{i}^{n}X_{i}+\left(n-\sum_{i=1}^{n}X_{i}\right)\ln\left(1-p\right)\\
        \dfrac{d\ln L\left(p|X_{1},\ldots,X_{n}\right)}{dp} &= \dfrac{\sum_{i=1}^{n}X_{i}}{p}-\dfrac{n-\sum_{i=1}^{n}X_{i}}{1-p}=0\\
        \hat{p}&= \dfrac{1}{n}\sum_{i=1}^{n}X_{i}
      \end{align}
      그러므로 $\ln\left(p/\left(1-p\right)\right)$의 MLE는 $\ln\left(\hat{p}/\left(1-\hat{p}\right)\right)$이다.
      \item 크레이머-라오 정보부등식은 다음의 세 가지 가정이 있다.
      \begin{itemize}
        \item 모수 공간이 열린 집합(open set)이어야 한다. ($\Theta$ is an open set.) 혹은 $\theta \in \Theta^{\circ}$, (여기서 $\Theta^{\circ}$은 $\Theta$의 interior임.)
        \item $\mathcal{Y}_{\theta}=\left\{y\in\mathcal{Y}|f_{Y}\left(y|\theta\right)>0 \right\}$이 모든 $\theta\in \Theta$에 대하여 같은 support을 가져야 한다.
        \item Dominated Convergence Theorem을 만족하는 함수 $g$가 존재해야 한다.(적분과 미분의 순서를 바꾸기 위함)
      \end{itemize}
      균일 분포는 일단 두 번째 가정이 깨지므로 크레이머-라오 부등식이 성립하지 않는다. 더 심각한 것은 균일분포는 score statistic (로그가능도함수를 모수에 대해 미분한 것)의 기댓값이 0이 되지 않는다는 점이다.
      $$
        \mathrm{E}\left(\dfrac{\partial}{\partial\theta}\ln f_{Y}\left(y|\theta\right)\right) = \int_{0}^{\theta}\dfrac{\partial}{\partial\theta}\dfrac{1}{\theta}\,dy \neq 0
      $$
      아무튼 안 된다.
    \end{enumerate}
   \end{solution}
   \question
   Let $X_{1},\ldots,X_{n}$ be a random sample from $f\left(x;\lambda\right)=\lambda\exp\left(-\lambda x\right)$, where $0<x<\infty$. The parameter $\lambda$ is $\lambda_{0}$ or $\lambda_{1}$, which is a known fixed number and $\lambda_{1}>\lambda_{0}$. We want to test $H_{0}:\lambda=\lambda_{0}$ versus $H_{1}:\lambda=\lambda_{1}$. Obtain the most powerful test, including the distribution of the test statistic.
   \begin{solution}
    
   \end{solution}
   \question
   Consider the linear model
   $$
    \bs{y}=\bs{X}\beta+\bs{e}
   $$
   with $\bs{y}=\begin{pmatrix}y_{1}\\y_{2}\end{pmatrix}$, $y_{1},y_{2}$ being scalar random variables, $\bs{X}$ is $\bs{X}=\begin{pmatrix}1 \\ 1 \end{pmatrix}$, with $\mathrm{E}\left(e\right)=\mathrm{E}\begin{pmatrix}e_{1}\\e_{2}\end{pmatrix}=\begin{pmatrix}0\\0\end{pmatrix}$ and $\mathrm{E}\left(\bs{ee}'\right)=\bs{\Sigma}_{ee}$ is known and invertible.
   \begin{enumerate}
    \item With $\bs{\Sigma}_{ee}=\begin{pmatrix}\sigma_{11} &\sigma_{12}\\\sigma_{21} & \sigma_{22} \end{pmatrix}$, determine the circumstances under which the BLUE(Best Linear Unbiased Estimator) of $\beta$ is equal to $y_{1}$. Hint: The BLUE of $\beta$, $\hat{\beta}_{\text{BLUE}}=\left(\bs{X}'\bs{\Sigma}^{-1}\bs{X}\right)^{-1}\bs{X}'\bs{\Sigma}^{-1}\bs{y}$, is obtained by solving the normal equation $\bs{X}'\bs{\Sigma}^{-1}\bs{X}\hat{\beta}_{\text{BLUE}}=\bs{X}'\bs{\Sigma}^{-1}\bs{y}$. Find the relationship among $\sigma_{ij}$'s such that the normal equation is free from $y_{2}$.
    \item With $\bs{\Sigma}_{ee}=\begin{pmatrix}\sigma_{11}& 0\\ 0 & \sigma_{22}\end{pmatrix} $ and $\beta=\mu$, find the BLUE of $\mu$ and its variance. Also derive the mean and variance of the arithmetic mean $\dfrac{y_{1}+y_{2}}{2}$. Compare the variance of two estimators and state your conclusion.
   \end{enumerate}
   \begin{solution}
    \begin{enumerate}
      \item Let $\bs{G}=\bs{\Sigma}^{-1/2}$. Then the model becomes
      $$
        \bs{Gy} = \bs{GX}\beta+\bs{Ge}
      $$
      and $\mathrm{Var}\left(\bs{Ge}\right)=\bs{G\Sigma G}^{T}=\bs{I}_{2}$. By LSE, BLUE is
      $$
        \argmin_{\beta}\left(\bs{Ge}\right)^{T}\left(\bs{Ge}\right)
      $$
      which, by plugging in the relationship, becomes
      $$
        \argmin_{\beta}\left(\bs{y}-\bs{X}\beta\right)^{T}\bs{G}^{T}\bs{G}\left(\bs{y}-\bs{X}\beta\right).
      $$
      Since $\bs{G}^{T}\bs{G}=\bs{G}^{2}=\bs{\Sigma}^{-1}$, the parts that include $\beta$ are
      $$
        \beta^{T}\bs{X}^{T}\bs{\Sigma}^{-1}\bs{X}\beta -2\beta^{T}\bs{X}^{T}\bs{\Sigma}^{-1}\bs{y}
      $$
      Differentiating w.r.t. $\beta$ yields
      $$
        2\beta^{T}\bs{X}^{T}\bs{\Sigma}^{-1}\bs{X} -2\bs{X}^{T}\bs{\Sigma}^{-1}\bs{y}=\bs{0}
      $$
      and arranging the result,
      $$
        \hat{\beta}_{\text{BLUE}} = \left(\bs{X}^{T}\bs{\Sigma}^{-1}\bs{X}\right)^{-1}\bs{X}^{T}\bs{\Sigma}^{-1}\bs{y}.
      $$
      이것을 문제에 주어진 것을 대입하여 전개하면 $\sigma_{11}=\sigma_{12}$이고 $\sigma_{2}\neq \sigma_{12}$일 때 BLUE가 $y_{1}$이 된다.
      \item BLUE of $\mu$ is
      \begin{align}
        \hat{\mu}_{\text{BLUE}} &= \dfrac{\sigma_{22}}{\sigma_{11}+\sigma_{22}}\left(\dfrac{1}{\sigma_{11}}y_{1}+\dfrac{1}{\sigma_{22}}y_{2}\right)\\
        &= \dfrac{\sigma_{22}}{\sigma_{11}+\sigma_{22}}y_{1}+\dfrac{\sigma_{11}}{\sigma_{11}+\sigma_{22}}y_{2}.
      \end{align}
      BLUE turns out to be the weighted mean of $y_{1}$ and $y_{2}$. Therefore, the expected value of BLUE is the parameter itself; hence, unbiased. The variance of BLUE is
      \begin{align}
        \mathrm{Var}\left(\hat{\mu}_{\text{BLUE}}\right) &= \left(\dfrac{\sigma_{22}}{\sigma_{11}+\sigma_{22}}\right)^{2}\sigma_{11}+\left(\dfrac{\sigma_{11}}{\sigma_{11}+\sigma_{22}}\right)^{2}\sigma_{22}\\
        &= \dfrac{\sigma_{11}\sigma_{22}}{\sigma_{11}+\sigma_{22}}.
      \end{align}
      And
      \begin{align}
        \mathrm{E}\left(\dfrac{y_{1}+y_{2}}{2}\right) &= \dfrac{1}{2}\left(\mathrm{E}\left(y_{1}\right)+\mathrm{E}\left(y_{2}\right)\right) = \mu
        \mathrm{Var}\left(\dfrac{y_{1}+y_{2}}{2}\right) &= \dfrac{1}{4}\left(\sigma_{11}+\sigma_{22}\right)
      \end{align}
      Both are unbiased but the variance of BLUE is smaller.
    \end{enumerate}
   \end{solution}
   \question
   $X_{n}$이 평균이 $n\lambda_{0}$인 포아송 분포를 따른다고 하고,
   $$
    Z_{n}=\dfrac{X_{n}-a_{n}}{b_{n}}
   $$
   이라고 하자. $n$이 무한대로 접근함에 따라 $Z_{n}$의 분포가 표준정규분포에 수렴하기 위한 수열 $a_{n}$과 $b_{n}$을 구하고, 이에 필요한 정리를 정확히 설명하시오.
   \begin{solution}
    중심극한정리는 분산이 유한한 확률변수가 여러개의 독립인 확률변수들의 합 꼴로 표현될 때 그 극한분포가 정규분포가 됨을 증명한 정리이다. $X_{n}\sim \mathrm{Poi}\left(n\lambda_{0}\right)$라면 $Y_{i}\overset{\text{iid}}{\sim} \mathrm{Poi}\left(\lambda_{0}\right),\; 1\leq i \leq n$을 이용하여 $X_{n}\equiv Y_{1}+\cdots+Y_{n}$로 재표현할 수 있다. 이때
    $$
      \sqrt{n}\dfrac{\left(\overline{X}_{n} -\mathrm{E}\left(Y_{1}\right)\right)}{\sqrt{\mathrm{Var}\left(Y_{1}\right)}}\sim \mathcal{N}\left(0,1\right)
    $$
    이므로 
    $$
      \sqrt{n}\dfrac{\left(\overline{X}_{n} -\mathrm{E}\left(Y_{1}\right)\right)}{\sqrt{\mathrm{Var}\left(Y_{1}\right)}} = \dfrac{X_{n}-n\lambda_{0}}{\sqrt{n\lambda_{0}}}
    $$
    로 $a_{n}=n\lambda_{0}$, $b_{n}=\sqrt{n\lambda_{0}}$임을 알 수 있다.
   \end{solution}
\end{questions}
\end{document}
